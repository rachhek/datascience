{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning\n",
    "Technique of combining multiple ML models to give better predictions than a single model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-What kind of individual learners to user?\n",
    "    - individual model could be of any type\n",
    "    - its better for the learner to be as different as possible from others.\n",
    "    - most preferred learners are decision trees\n",
    "    - an ensemble of decision trees is a random forest  \n",
    "- How should individual learners be trained?\n",
    "    - if learners are different, each learner can be trained on the entire dataset\n",
    "    - for similar learners, each model can be trained on subset of data or random set of features\n",
    "- How should individual learners be combined?\n",
    "    - in case of classification : use hard voting ie majority vote of individual learners\n",
    "    - soft voting : (classification and regression) probability-weighted average\n",
    "    - stacking : train additional model from the output of the earlier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning techniques\n",
    "We can train an ensemble in one of two ways:\n",
    "- averaging\n",
    "    - train predictors in parallel and average scores of individual predictors\n",
    "- boosting\n",
    "    - train predictors in sequence where each predictor learns from earlier mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting and Stacking\n",
    " - Voting : majority vote of the individual predictors is the final prediction of the ensemble\n",
    " - Stacking : fit a model on the individual predictions to get the final predictions of the ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging\n",
    "- trains multiple learners in parallel in the data\n",
    "- each individual learner predictinos from each learner\n",
    "- final prediction of the ensemble is an average of individual predictions\n",
    "- Voting can be an considered part of voting\n",
    "- individual training model on different samples of training data\n",
    "    - Bagging: sample data with replacement\n",
    "    - Pasting: sample data without replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "- trains multiple learners sequentially\n",
    "- each model takes the output form the first model as an input\n",
    "- can tweak the learning rate or contribution of each model\n",
    "- addition of a learner boosts the accuracy of the model\n",
    "- two boosting techniques\n",
    "    - adaptive boosting: each model pays more attention to training instances the previuos model got wrong\n",
    "    - gradient boosting: each model in sequence fits on residual erros of the pevious model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting\n",
    "- each individual predictions from each learner\n",
    "- each learner uses different training algorithm\n",
    "- the different algorithms add diversity to the predictions\n",
    "- types of voting\n",
    "    - hard voting : for classfication ; where final output of the ensemble is the majority vote\n",
    "    - soft voting : final output of the ensemble is the category with the highest probability score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking:\n",
    "- train diverse individual learners\n",
    "- get predictions from individual predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree in Ensemble Learners\n",
    "- individual learners can be of any type\n",
    "- individual learners should be as different as possible so that different patterns are learned\n",
    "- Decision tree are high variance machine learning model\n",
    "- decision tree are very senstive to data\n",
    "- so that is why decision tree is trusted to capture many patterns.\n",
    "\n",
    "## Random forest\n",
    "- collection of decision tree\n",
    "- different decision tree is trained on different subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Random forest:\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
